
# **1.2 AI テストの原則 (Principles of AI Testing)**

**信頼できる AI (Trustworthy AI)** は三つの基礎ドメイン **責任ある AI (Responsible AI (RespAI))**、**セキュリティ AI (Security AI (SecAI))**、**プライバシー AI (Privacy AI (PrivacyAI))** の強みを組み合わせることで達成されます。
これらのドメインは **OWASP AI Testing Framework** の中で信頼できる AI の *テスト可能な基盤* を形成します。
信頼できる AI のより広い定義には、ガバナンス、信頼性、説明責任を包含することもありますが、これらの特性は、以下の三つのドメインにわたる **継続的なテスト実行** を通じて可能となり、運用されます。

効果的な AI テストは以下の側面を総合的に統合します。

* **セキュリティ** は、敵対的脅威やインフラストラクチャへの脅威に対する耐性を確保します。
* **プライバシー** は、機密性を保護し、機密データの悪用や推測を防止します。
* **責任ある AI** は、倫理的であり、透明性があり、バイアスのない動作を強制します。

全体として、**信頼できる AI システム** (安全であり、予測可能であり、人間の価値観に沿って動作するシステム) を検証、制御、維持するための統一された構造を形成します。

### **1. セキュリティ (SecAI)**

AI システムは敵対的脅威とシステム全体の悪用に耐性を持つ必要があり、AI スタックとライフサイクル全体にわたる保護を確保します。

* **プロンプトと入力の制御:** システムプロンプト、命令、ユーザー入力をインジェクションや不正操作から保護します。
* **敵対的堅牢性:** 回避、ポイズニング、モデル窃取、ジェイルブレイク、間接プロンプトインジェクションへの耐性をテストします。
* **インフラストラクチャセキュリティ:** API エンドポイント、プラグイン、RAG パイプライン、エージェントワークフローの脆弱性を評価します。
* **サプライチェーンリスク:** ポイズニング、改竄、サードパーティの侵害についてモデルと依存関係を検査します。
* **継続的テスト実行:** CI/CD パイプラインに自動的な敵対的スキャンおよび依存関係スキャンを統合します。

### **2. プライバシー (PrivacyAI)**

モデルのライフサイクル全体を通じて、AI システムに開示されるデータ、または AI システムによって生成されるデータの機密性とユーザー制御を確保します。

* **データ漏洩防止:** トレーニングデータ、プライベートコンテキスト、ユーザー入力の意図しない開示を検出します。
* **メンバーシップとプロパティの推論耐性:** データがトレーニングの一部であるかどうかを推論する攻撃に対する影響の受けやすさを評価します。
* **モデルの抽出と流出:** プロプライエタリモデルや重みを複製しようとする攻撃者をシミュレートします。
* **データガバナンスコンプライアンス:** 最小化、目的の制限、同意管理の原則の順守を検証します。

### **3. 責任ある AI (RespAI)**

継続的な評価と緩和策を通じて、倫理的であり、安全であり、整合性のあるシステム動作を促進します。

* **バイアスと公平性の監査:** 人口統計グループやエッジケースにおける差別的な出力を特定します。
* **有毒性と不正使用の検出:** 有害なコンテンツや誤解を招くコンテンツの作成や拡散に対する耐性をテストします。
* **安全アライメント:** アライメント制約への遵守と、ジェイルブレイクやロールプレイエクスプロイトへの耐性を検証します。
* **ガードレールのカバレッジ:** 安全フィルタ、拒否メカニズム、不正使用防止ロジックを評価します。
* **Human-in-the-Loop 制御:** 影響の大きい意思決定についてはエスカレーションとレビュー経路を確保します。

### **4. 信頼できる AI システム**

**信頼できる AI = RespAI + SecAI + PrivacyAI** は、ガバナンス、透明性、長期にわたる信頼を維持する監視メカニズムによって支えられています。

* **説明可能性:** ユーザーと監査者が意思決定の方法と理由を理解できるようにします。
* **一貫性と安定性:** プロンプトの変動と回帰テストにおいて予測可能なレスポンスを検証します。
* **継続的な監視:** ランタイム可観測性、ドリフト検出、自動異常アラートを適用します。
* **ライフサイクルテスト:** 設計からデプロイメント、および市場投入後の段階までバリデーションを拡張します。
* **ポリシーと規制への適合:** テストとバリデーションプロセスを **NIST AI RMF [1]**, **ISO/IEC 42001 [2]**, **OWASP Top 10 for LLMs [3]** などのフレームワークにマップします。








効果的な AI テストは、信頼できる AI システムを構築するために、セキュリティ、プライバシー、責任ある AI という三つのマクロドメインを基盤としています。これらの 3 つのコアドメインを選んだのは、AI リスク全体をまとめて対処できるためです。セキュリティは敵対的脅威やインフラストラクチャの脅威に対する耐性を確保します。プライバシーは意図しないデータ開示や推論攻撃を防止します。責任ある AI は倫理的動作と公平性を重視し、バイアスや不正使用から保護します。全体として、安全で信頼できる AI デプロイメントを検証、制御、維持するための包括的なフレームワークを形成します。各ドメインには、最新の AI アプリケーションの評価を導く重要な原則を含みます。

### **AI をテストする時期 (When to Test AI)**

ISO/IEC 23053 \[4\] は、ML ベースの AI システムライフサイクルを、それぞれの明確な目標、アーティファクト、ガバナンスのタッチポイントでの、一連の繰り返し可能なフェーズに構造化しています。

1. **計画とスコープ設定:** このフェーズでは、主要な利害関係者、規制要件、組織のリスク許容度を特定しながら、明確なビジネス目標、成功指標、ML ユースケースを確立します。
2. **データ準備:** このフェーズでは、未加工のデータソースを収集して文書化し、前処理パイプラインを通じてプロファイリングと品質チェックを実施し、完全なデータトレーサビリティのためにバージョン管理とリネージュ追跡を実装します。
3. **モデルの開発とトレーニング:** このフェーズでは、適切なアルゴリズムとアーキテクチャを選択し、特徴エンジニアリングを用いて厳選されたデータセットでモデルを訓練し、学習プロセスを制御するパラメータ (つまりハイパーパラメータ) やパフォーマンスメトリクスなどの実験をモデルレジストリに記録します。
4. **バリデーションと評価:** このフェーズでは、予約済みの敵対的データセットを使用してモデルをテストし、公平性、堅牢性、セキュリティ評価を実行し、機能、倫理、規制の基準を満たすことを確認します。
5. **デプロイメントと統合:** このフェーズでは、訓練済み AI モデルを準備し、サービス (つまりマイクロサービスまたは API でモデルをラップする) またはエッジデプロイメント (つまり IoT ゲートウェイやモバイルフォンなどのリソースに制限のあるデバイス向けにモデルを変換および最適化する) 用のデプロイ可能なアーティファクトにバンドルし、CI/CD を介してビルド、テスト、リリースのワークフローを自動化し、インフラストラクチャのセキュリティ対策を検証します。
6. **運用と保守:** このフェーズでは、AI 製品が実稼働環境にある間、パフォーマンス、データドリフト、監査ログを継続的に監視し、異常やコンプライアンス違反のアラートをトリガーするとともに、定期的に最新データでモデルを再訓練し、セキュリティ、プライバシー、公平性のコントロールを再検証し、必要に応じてドキュメント、トレーニング、ポリシーを更新します。

AI システムが開始から継続的な運用まで正確、安全、公平、信頼を維持することを確保するには、AI テストは AI システムライフサイクル全体にわたって統合される必要があります。

1. **計画とスコープ設定のフェーズ:** ビジネス目標、成功指標、ML ユースケースがテスト可能かつ追跡可能であることを確認します。AI 固有のリスク (敵対的リスク、プライバシーリスク、コンプライアンスリスク) を特定し、それらをコントロールにマップします。利害関係者の役割、規制上の制約、リスク許容基準が文書化されていることを検証します。
2. **データ準備:** データ品質テストを実施し、欠損値、外れ値、スキーマの不一致、重複についてチェックします。特徴量分布 (つまり特定の変数量がどのように分布または配置されているか) を履歴プロファイルに対して検証し、ドリフト閾値 (つまりこのベースラインからのデータドリフトに対して) を設定します。すべてのデータソース、変換、バージョンが記録され、追跡可能であることを確認します。
3. **モデルの開発とトレーニング:** 前処理コード、カスタムレイヤ、特徴量エンジニアリング関数が期待通りに動作することを検証します。モデルコードに対して安全でない依存関係や構成ミスについて静的コードスキャン (SAST など) を実行します。トレーニング、バリデーション、テストのスプリット間でデータ漏洩がないことを確認します。チューニングの変更が回帰なしで汎化を向上することを確認します。
4. **バリデーションと評価:** ホールドアウトおよび敵対的テストセットにおいて、正確さ、適合率/再現率、AUC などを測定するためのベンチマークに対するパフォーマンスを検証します。公平性とバイアスの監査を実施し、人口統計スライスおよびエッジケースにわたってモデル出力を評価します。ニューラルネットワークやその他の敵対的攻撃に対する敵対的サンプルを細工するための既知の技法を適用することで、敵対的堅牢性テストを実施し、体制を評価します。プライバシー攻撃を実施し、メンバーシップ推論、モデル抽出、ポイズニングをシミュレートしてプライバシー保護を確認します。予測を入力特徴量に帰属することにより、モデルの決定が解釈可能かつ妥当であることを検証します。
5. **運用と保守:** 実稼働の入力と出力をバリデーションベースラインと継続的に比較することにより、ドリフト検出のための回帰テストを実施します。パフォーマンス低下、データドリフト、セキュリティ異常の際に監視ルールが正しく発火することを検証します。モデルアップデートまたはデータリフレッシュ後に、パフォーマンス、公平性、堅牢性を再評価します。セキュリティ、プライバシー、倫理的コントロールが引き続き有効であり、文書化されていることを定期的に確認します。

このガイドのテスト目標の一つは、OWASP の LLM 固有のテストケースと、より広範な OWASP AI Exchange \[5\] の脅威をライフサイクルフェーズに統合し、リリース前バリデーションと新たな脆弱性に対する継続的な保護の両方を確保することです。たとえば、計画とスコープ設定のフェーズで、脅威モデリング演習を使用して、OWASP Top 10 LLM リスク (プロンプトインジェクション、データ漏洩、モデルポイズニング、過度の依存など) と AI Exchange の脅威を列挙し、テストスコープとコントロールを定義できます。

たとえば、バリデーションと評価のフェーズでは、プロンプトインジェクションテストで直接および間接プロンプト不正操作をテストし、ガードレールのカバレッジと拒否動作を検証します。また、制御された再トレーニングループに悪意のあるサンプルを注入して、ポイズニング防御が機能することを確認します。開発と運用では、新しくインストールまたはアップデートされたプラグインを継続的にスキャンして、OWASP で特定された弱点を検出し、ジェイルブレイク、バックドアプロンプト、既知の OWASP AI Exchange 脅威ベクトルの悪用の兆候がないか、出力を監視するようにテストを指示できます。

この初期リリースでは、OWASP AI テスト方法論は AI 製品の所有者をガイドすることに重点を置いており、AI 製品の初期バージョンがテスト準備できたら、テストスコープを定義し、包括的な一連の評価を実行できます。今後のアップデートではこのガイダンスを拡張し、より初期の試作フェーズもカバーする予定です。
