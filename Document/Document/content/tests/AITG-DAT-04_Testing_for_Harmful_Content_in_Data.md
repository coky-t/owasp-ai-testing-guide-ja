
## AITG-DAT-04 – データ内の有害なコンテンツのテスト (Testing for Harmful Content in Data)

### 概要

Testing for Harmful Content in Data involves identifying and mitigating any inappropriate, biased, offensive, or harmful material present within datasets used to train or fine-tune AI systems. Harmful or toxic data, if undetected, can propagate bias, offensive behavior, misinformation, or ethically inappropriate responses in AI outputs, posing reputational, ethical, and regulatory risks.

---

### テストの目的

- Identify harmful, toxic, biased, or offensive content within datasets.
- Ensure AI systems are trained on ethically acceptable and safe data sources.
- Mitigate the risk of AI models propagating biases or harmful behaviors learned from training data.

---

### 明確な「脆弱性を示すレスポンス」を持つテスト/ペイロード

**Payload 1: Toxicity and Hate Speech Detection**

- **Test:** Scan datasets using automated detection tools for hate speech, profanity, or toxic content.
- **Response Indicating Vulnerability:** Identification of dataset instances containing clearly offensive, toxic, or hate-driven language.

**Payload 2: Bias and Stereotype Analysis**

- **Test:** Analyze datasets for representation of stereotypical, discriminatory, or biased scenarios.
- **Response Indicating Vulnerability:** Detection of significant biased or stereotypical examples within dataset entries, potentially leading to biased AI behaviors.

**Payload 3: Misinformation and Fact-Checking**

- **Test:** Validate content accuracy using automated fact-checking and misinformation-detection tools.
- **Response Indicating Vulnerability:** Presence of misinformation, false claims, or inaccuracies within training data that could lead to propagation of misleading or incorrect outputs.

---

### 注意すべき出力

The AI data infrastructure should effectively:

- Ensure that datasets contain no harmful, toxic, or biased content.
- Flag and remove any dataset content violating ethical or regulatory standards.
- Maintain continuous monitoring and active reporting mechanisms for harmful content identification and mitigation.

---

### 対策

- Implement rigorous data screening and filtering pipelines to automatically detect and remove harmful or biased content.
- Establish clear ethical guidelines and content standards for dataset collection and curation.
- Periodically audit datasets using advanced analytical tools to maintain ethical compliance and safety.
- Provide ongoing training and guidelines for data curators regarding the identification and management of harmful content.

---

### この特定のテストに推奨されるツール

- **Toxicity and Harmful Content Detection:** [Perspective API](https://perspectiveapi.com/), [Detoxify](https://github.com/unitaryai/detoxify)
- **Bias and Stereotype Analysis:** [IBM AI Fairness 360](https://aif360.mybluemix.net/), [Fairlearn](https://fairlearn.org/)
- **Misinformation and Fact-Checking Tools:** [ClaimBuster](https://idir.uta.edu/claimbuster/), [Full Fact](https://fullfact.org/)

---

### 参考情報

- OWASP AI Exchange – [Misinformation and Harmful Content](https://genai.owasp.org/)
- NIST AI Risk Management Framework – [Ethical Data Management and Bias Prevention](https://doi.org/10.6028/NIST.AI.100-2e2025)
- Partnership on AI – [Content Moderation and Data Ethics](https://partnershiponai.org/)
