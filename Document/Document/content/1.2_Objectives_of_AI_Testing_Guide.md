# 1.2 OWASP AI テストガイドの目的 (Objectives of OWASP AI Testing Guide)

OWASP は長年にわたりウェブアプリケーションのセキュリティガイドラインの策定をリードしてきましたが、今日ではそのリーダーシップを AI にも拡大しています。AI テストガイドは、AI システムの堅牢性、信頼性、耐性を評価するための、構造化された実践的なフレームワークを提供します。AI セキュリティテスト担当者、監査担当者、レッドチーム専門家、MLOps エンジニア、開発者が、AI アプリケーション、モデル、インフラストラクチャ、データパイプラインによってもたらされる固有のリスクを特定、モデル化、検証できるように支援します。

### このガイドの対象者

オープンコミュニティのコラボレーションを通じて世界中のソフトウェアのセキュリティを向上するという OWASP の使命に沿って、AI テストガイドは以下の方々に向けて設計されています。
- AI セキュリティテスト担当者。標準的な脆弱性スキャンの枠を超え、モデルの動作と敵対的耐性を詳細に評価したい方。
- AI 監査担当者とコンプライアンスチーム。AI システムが責任ある AI の原則と業界規制を満たすことを検証することを担う方。
- AI エンジニア、開発者、MLOps 専門家。耐性があり信頼できる AI パイプラインとサービスを構築するための、実践的で実用的なガイダンスを求めている方。
- AI レッドチームメンバー。敵対的評価や生成 AI レッドチーミング演習を実施し、見つけにくい脆弱性をあばく方。  
上記の役割に加えて、この OWASP AI テストガイドは従来のセキュリティチームをはるかに超えて、プロダクトオーナー、リスクおよびガバナンス担当者、QA エンジニア、DevSecOps 実践者、インシデント対応担当者、学術研究員を支援することを目的としています。OWASP のオープンコラボレーションモデルの下で、この多様なコミュニティを結集することによって、グローバルな専門知識を活用し、世界中の AI セキュリティの水準を向上します。

### 方法論: 脅威モデリングからテストまで

In the OWASP AI Testing Guide, we employ a threat-driven methodology. AI systems present distinct, high-impact risks, ranging from adversarial exploits to privacy infringements and demand that we allocate our resources to scenarios most likely to affect business operations or user safety. By first conducting threat modeling and mapping, and then developing targeted test cases, we ensure that every assessment addresses the AI-specific threats most relevant to our system architecture and risk tolerance.
This guide is structured around a clear methodology:
- Threat Modeling: We begin by constructing a high-level AI system diagram, decomposing it into four key components, Application, Model, Infrastructure, and Data. This architectural view highlights trust boundaries and critical interactions where threats may arise.
- Threat Mapping: Identified threats are cataloged against established sources, including:
-- OWASP Top 10 for LLMs
-- OWASP AI Exchange
-- Responsible AI and Trustworthy AI frameworks
- Test Design: For each mapped threat, we develop tailored test cases that specify:
-- Example Payloads: Concrete inputs or manipulations designed to trigger the threat.
-- Expected Outcome: The correct system response or failure mode.
-- Detection Strategy: How to monitor, log, or alert on indicators of compromise.
-- Tool Recommendations: Open-source or commercial tools suited to each test.
By following these steps, teams can move seamlessly from understanding AI-specific risks to validating defenses through practical, repeatable tests.

### このプロジェクトでカバーしないもの

This guide does not attempt to replace or duplicate existing foundational security testing methodologies. Instead, it complements them by focusing on AI-specific threats. For general system and application security, we recommend the following best-in-class references:
- Network Security: NIST SP 800-115 [6], Technical Guide to Information Security Testing and Assessment
- Infrastructure Security: OSSTMM [7], Open Source Security Testing Methodology Manual
- Web Application Security: OWASP Web Security Testing Guide (WSTG) [8]
