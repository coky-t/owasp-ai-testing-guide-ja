# 1. はじめに

### AI の信頼性の基盤としての AI テスト

Artificial Intelligence has shifted from an innovative technology to a critical component of modern digital infrastructure. AI systems now support high-stakes decisions in healthcare, finance, mobility, public services, and enterprise automation. As these systems grow in reach and autonomy, organizations need a standardized and repeatable way to verify that AI behaves safely as intended.

The OWASP AI Testing Guide fills this gap by establishing a practical standard for trustworthiness testing of AI systems, offering a unified, technology-agnostic methodology that evaluates not only security threats but the broader trustworthiness properties required by responsible and regulatory-aligned AI deployments.

AI testing is no longer just about security, it is a multidisciplinary discipline focused on maintaining trust in autonomous and semi-autonomous systems.  The OWASP AI Testing Guide establishes the missing standard: a unified, practical, and comprehensive framework for trustworthiness testing of AI systems, grounded in real attack patterns, emerging global standards, and the lived experience of the AI security community.

### AI テストがユニークな理由

Traditional software testing focuses on protecting systems from unauthorized access, code flaws, and system vulnerabilities. AI systems require more. Because AI models learn, adapt, generalize, and fail in non-deterministic ways, they introduce risks that cannot be addressed with conventional security testing.

From the evidence documented in the NIST AML Taxonomy and the OWASP Top 10 for LLM Applications 2025 , we know that AI systems fail for reasons that go far beyond security:

* Adversarial manipulation (prompt injection, jailbreaks, model evasion)
* Bias and fairness failures
* Sensitive information leakage
* Hallucinations and misinformation
* Data/model poisoning across the supply chain
* Excessive or unsafe agency
* Misalignment with user intent or organizational policies
* Non-transparent or unexplainable outputs
* Model drift and degradation over time
  
Because of these complexities, the industry is converging on the principle that:
Security is not sufficient, AI Trustworthiness is the real objective.
This OWASP AI Testing Guide operationalizes these principles into a practical testing framework.

AI モデルは、巧妙に細工された入力 (敵対的サンプル) によって欺かれたり操作される可能性があります。組織は標準的な機能テストをはるかに超える専用の敵対的堅牢性テスト方法論を採用する必要があります。これらの専門的なセキュリティ評価がなければ、AI システムは完全性、信頼性、全体的な信憑性を損なう可能性のある巧妙な攻撃に脆弱なままとなります。


### OWASP AI テストガイドの目的とスコープ

The OWASP AI Testing Guide provides:
* A standardized methodology for trustworthiness testing of AI and LLM-based systems 
* Repeatable test cases that evaluate risks across:
  - AI Application Layer
  - AI Model Layer
  - AI Infrastructure Layer
  - AI Data Layer

本ガイドは、ソフトウェア開発者、アーキテクト、データアナリスト、研究者、監査担当者、リスク担当者にとっての包括的なリファレンスとして機能するように設計されており、製品開発ライフサイクル全体を通じて AI リスクが体系的に対処されることを確保します。

このガイダンスに従うことで、チームは AI システムを自信を持って本番環境にデプロイするために必要なレベルの信頼を確立し、潜在的なバイアス、脆弱性、パフォーマンス低下が事前に特定されて緩和される、検証可能な保証を得ることが可能です。
