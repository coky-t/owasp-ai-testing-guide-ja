# **1.1 AI テストの原則 (Principles of AI Testing)**

効果的な AI テストは、セキュリティ、プライバシー、責任ある AI、信頼できる AI システムという四つのマクロドメインを基盤としています。これらの四つのコアドメインを選んだのは、AI リスク全体をまとめて対処できるためです。セキュリティは敵対的脅威やインフラストラクチャの脅威に対する耐性を確保します。プライバシーは意図しないデータ開示や推論攻撃を防止します。責任ある AI は倫理的動作と公平性を重視し、バイアスや不正使用から保護します。信頼できる AI システムは、説明可能性、安定性、ガバナンスの整合性を通じて、継続的な信頼性を維持します。全体として、安全で信頼できる AI デプロイメントを検証、制御、維持するための包括的なフレームワークを形成します。各ドメインには、最新の AI アプリケーションの評価を導く重要な原則を含みます。

### **1\. セキュリティ (Security)**

AI システムは敵対的脅威とシステム全体の悪用に耐性を持つ必要があります。これは、モデルの堅牢性だけでなく、スタック全体のセキュリティも含みます。

* **プロンプトと入力の制御:** システムプロンプト、命令、ユーザー入力がインジェクションや不正操作から保護されていることを確認します。
* **敵対的堅牢性:** 回避、ポイズニング、モデル窃取、ジェイルブレイク、間接プロンプトインジェクションへのシステムの耐性を検証します。
* **インフラストラクチャセキュリティ:** API エンドポイント、プラグイン、RAG パイプライン、エージェントワークフローの脆弱性を評価します。
* **サプライチェーンリスク**: ポイズニング、不正改竄、サードパーティの侵害についてモデルと依存関係をテストします。

### **2\. プライバシー (Privacy)**

Ensure confidentiality and control over sensitive data exposed to or generated by AI systems.

* **Data Leakage Prevention:** Test against unintended disclosure of training data, private context, or user inputs.  
* **Membership & Property Inference Resistance**: Assess model exposure to privacy attacks that infer if specific data was used in training.  
* **Model Extraction & Exfiltration:** Simulate attacks that try to copy or replicate proprietary models.

### **3\. 責任ある AI (Responsible AI)**

Promote safe, ethical, and aligned outcomes through ongoing evaluation and mitigation strategies.

* **Bias & Fairness Audits:** Identify discriminatory outputs and test model behavior across diverse demographic groups and edge cases.  
* **Toxicity & Abuse Detection**: Validate how models handle hate speech, misinformation, and harmful outputs.  
* **Safety Alignment**: Evaluate the system’s response to alignment bypass attacks (e.g., DAN, roleplay exploits).  
* **Guardrail Coverage:** Test safety filters, refusal behaviors, and abuse-prevention mechanisms.

### **4\. 信頼できる AI システム (Trustworthy AI Systems)**

Support long-term confidence through transparency, monitoring, and governance.

* **Explainability**: Ensure users and auditors can understand how and why decisions are made.  
* **Consistency & Stability:** Test models for response variance, regressions, and unexpected behavior under slight prompt changes.  
* **Continuous Monitoring:** Apply post-deployment observability, drift detection, and incident alerting.  
* **Policy & Regulatory Alignment:** Ensure testing processes and system behaviors comply with frameworks like NIST AI RMF \[1\], ISO 42001 \[2\], and OWASP Top 10 LLM \[3\].

---

### **AI をテストする時期 (When to Test AI)**

ISO/IEC 23053 \[4\] structures the ML-based AI system lifecycle into a series of repeatable phases, each with clear objectives, artifacts, and governance touchpoints:

1. **Planning & Scoping:** In this phase, you establish clear business objectives, success metrics, and ML use cases while identifying key stakeholders, regulatory requirements, and the organization’s risk tolerance.  
2. **Data Preparation:** In this phase, you gather and document raw data sources, conduct profiling and quality checks through preprocessing pipelines, and implement versioning and lineage tracking for full data traceability.  
3. **Model Development & Training:** In this  phase, you choose appropriate algorithms and architectures, train models on curated datasets with feature engineering, and record experiments, including the parameters that govern the learning process (i.e hyperparameters) and performance metrics in a model registry.  
4. **Validation & Evaluation:** in this phase, you test models using reserved and adversarial datasets, perform fairness, robustness, and security evaluations, and ensure they meet functional, ethical, and regulatory standards.  
5. **Deployment & Integration:** in this phase, you are preparing and bundling your trained AI model into a deployable artifact for either service (i.e. wrap the model in a microservice or API) or edge deployment (i.e. convert and optimize the model for resource-constrained devices such as IoT gateways or mobile phones)  automate build-test-release workflows via CI/CD, and verify infrastructure security measures   
6. **Operation & Maintenance:** in this phase while the AI product is in production environment, you will continuously monitor performance, data drift, and audit logs, triggering alerts on anomalies or compliance breaches, while periodically retraining models with fresh data, re-validating security, privacy, and fairness controls, and updating documentation, training, and policies as needed.

AI testing should be integrated throughout the entire AI system lifecycle to ensure AI systems remain accurate, secure, fair, and trustworthy from inception through ongoing operation:

1. **Planning & Scoping Phase:** Confirm that business objectives, success metrics, and ML use cases are testable and traceable. Identify AI-specific risks (adversarial, privacy, compliance) and map them to controls. Verify stakeholder roles, regulatory constraints, and risk-tolerance criteria are documented.  
2. **Data Preparation:** Perform data quality tests to check for missing values, outliers, schema mismatches, and duplicates.Validate feature distributions (i.e. how the values of a particular variable are spread out or arranged) against historical profiles to set drift thresholds (i.e. for data drifts from this baseline). Ensure every data source, transformation, and version is recorded and traceable.  
3. **Model Development & Training:** Validate preprocessing code, custom layers, and feature engineering functions behave as expected. Run static code scans (e.g. SAST) on model code for insecure dependencies or misconfigurations. Confirm no data leakage between training, validation, and test splits. Ensure tuning changes improve generalization without regressions.  
4. **Validation & Evaluation:** Validate performance against benchmarks to measure accuracy, precision/recall, AUC, etc., on hold-out and adversarial test sets. Conduct fairness & bias audits to evaluate model outputs across demographic slices and edge cases. Conduct adversarial robustness tests by applying well-known techniques for crafting adversarial examples against neural networks or other adversarial attacks to assess resistance. Conduct privacy attacks to simulate membership inference, model extraction, and poisoning to confirm privacy protections. Verify model decisions are interpretable and valid by attributing predictions back to input features.  
5. **Operation & Maintenance:** Conduct regression tests for drift detection by Continuously comparing production inputs and outputs to validation baselines. Verify monitoring rules fire correctly on performance dips, data drift, or security anomalies.Re-evaluate performance, fairness, and robustness after model updates or data refreshes. Periodically confirm that security, privacy, and ethical controls remain effective and documented.

Among the testing goals of this guide is to integrate OWASP’s LLM‐specific test cases and broader OWASP AI Exchange \[5\] threats into your lifecycle phases to ensure both pre‐release validation and continuous protection against emerging vulnerabilities. During planning and scoping phase for example threat modeling exercises can be used to enumerate OWASP Top 10 LLM risks (prompt injection, data leakage, model poisoning, over‐reliance, etc.) and AI Exchange threats to define your test scope and controls. 

During the Validation & Evaluation phase for example, prompt injection tests can test direct and indirect prompt manipulations to verify guardrail coverage and refusal behaviors and Inject malicious samples in a controlled retraining loop to ensure poisoning defenses work, During development & operation tests can be directed to continuously scan newly installed or updated plugins for OWASP‐identified weaknesses and to monitor outputs for signs of jailbreaks, back‐door prompts, or exploitation of known OWASP AI Exchange threat vectors.

In this initial release, the OWASP AI testing methodology is focused on guiding AI product owners to define the test scope and execute a comprehensive suite of assessments once an initial AI product version is test-ready; future updates will expand this guidance to cover earlier pre-production phases as well.
