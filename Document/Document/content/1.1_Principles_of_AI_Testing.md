# **1.1 AI テストの原則 (Principles of AI Testing)**

効果的な AI テストは、セキュリティ、プライバシー、責任ある AI、信頼できる AI システムという四つのマクロドメインを基盤としています。これらの四つのコアドメインを選んだのは、AI リスク全体をまとめて対処できるためです。セキュリティは敵対的脅威やインフラストラクチャの脅威に対する耐性を確保します。プライバシーは意図しないデータ開示や推論攻撃を防止します。責任ある AI は倫理的動作と公平性を重視し、バイアスや不正使用から保護します。信頼できる AI システムは、説明可能性、安定性、ガバナンスの整合性を通じて、継続的な信頼性を維持します。全体として、安全で信頼できる AI デプロイメントを検証、制御、維持するための包括的なフレームワークを形成します。各ドメインには、最新の AI アプリケーションの評価を導く重要な原則を含みます。

### **1\. セキュリティ (Security)**

AI システムは敵対的脅威とシステム全体の悪用に耐性を持つ必要があります。これは、モデルの堅牢性だけでなく、スタック全体のセキュリティも含みます。

* **プロンプトと入力の制御:** システムプロンプト、命令、ユーザー入力がインジェクションや不正操作から保護されていることを確認します。
* **敵対的堅牢性:** 回避、ポイズニング、モデル窃取、ジェイルブレイク、間接プロンプトインジェクションへのシステムの耐性を検証します。
* **インフラストラクチャセキュリティ:** API エンドポイント、プラグイン、RAG パイプライン、エージェントワークフローの脆弱性を評価します。
* **サプライチェーンリスク**: ポイズニング、不正改竄、サードパーティの侵害についてモデルと依存関係をテストします。

### **2\. プライバシー (Privacy)**

AI システムに開示される、または AI システムによって生成される機密データの機密性と制御を確保します。

* **データ漏洩防止:** トレーニングデータ、プライベートコンテキスト、ユーザー入力の意図しない開示に対してテストします。
* **メンバーシップとプロパティの推論耐性**: 特定のデータがトレーニングに使用されているかどうかを推論するプライバシー攻撃に対するモデルの露出を評価します。
* **モデルの抽出と流出:** プロプライエタリモデルをコピーまたは複製しようとする攻撃をシミュレートします。

### **3\. 責任ある AI (Responsible AI)**

継続的な評価と緩和戦略を通じて、安全で倫理的かつ整合性のある結果を促進します。

* **バイアスと公平性の監査:** 差別的な出力を特定し、多様な人口統計グループとエッジケースにわたってモデルの動作をテストします。
* **有毒性と不正使用の検出**: モデルがヘイトスピーチ、誤情報、有害な出力をどのように処理するかを検証します。
* **安全アラインメント**: アラインメントバイパス攻撃 (DAN、ロールプレイエクスプロイトなど) に対するシステムのレスポンスを評価します。
* **ガードレールのカバレッジ:** 安全フィルタ、拒否行動、不正使用防止メカニズムをテストします。

### **4\. 信頼できる AI システム (Trustworthy AI Systems)**

透明性、監視、ガバナンスを通じて長期的な信頼性をサポートします。

* **説明可能性**: ユーザーと監査者が意思決定の方法と理由を理解できるようにします。
* **一貫性と安定性:** プロンプトをわずかに変更した場合のレスポンスの変動、回帰、予期しない動作についてモデルをテストします。
* **継続的な監視:** デプロイメント後の可観測性、ドリフト検出、インシデントアラームを適用します。
* **ポリシーと規制への適合:** テストプロセスとシステム動作が NIST AI RMF \[1\], ISO 42001 \[2\], OWASP Top 10 LLM \[3\] などのフレームワークに準拠していることを確認します。

---

### **AI をテストする時期 (When to Test AI)**

ISO/IEC 23053 \[4\] は、ML ベースの AI システムライフサイクルを、それぞれの明確な目標、アーティファクト、ガバナンスのタッチポイントでの、一連の繰り返し可能なフェーズに構造化しています。

1. **計画とスコープ設定:** このフェーズでは、主要な利害関係者、規制要件、組織のリスク許容度を特定しながら、明確なビジネス目標、成功指標、ML ユースケースを確立します。
2. **データ準備:** このフェーズでは、未加工のデータソースを収集して文書化し、前処理パイプラインを通じてプロファイリングと品質チェックを実施し、完全なデータトレーサビリティのためにバージョン管理とリネージュ追跡を実装します。
3. **モデルの開発とトレーニング:** このフェーズでは、適切なアルゴリズムとアーキテクチャを選択し、特徴エンジニアリングを用いて厳選されたデータセットでモデルを訓練し、学習プロセスを制御するパラメータ (つまりハイパーパラメータ) やパフォーマンスメトリクスなどの実験をモデルレジストリに記録します。
4. **バリデーションと評価:** このフェーズでは、予約済みの敵対的データセットを使用してモデルをテストし、公平性、堅牢性、セキュリティ評価を実行し、機能、倫理、規制の基準を満たすことを確認します。
5. **デプロイメントと統合:** このフェーズでは、訓練済み AI モデルを準備し、サービス (つまりマイクロサービスまたは API でモデルをラップする) またはエッジデプロイメント (つまり IoT ゲートウェイやモバイルフォンなどのリソースに制限のあるデバイス向けにモデルを変換および最適化する) 用のデプロイ可能なアーティファクトにバンドルし、CI/CD を介してビルド、テスト、リリースのワークフローを自動化し、インフラストラクチャのセキュリティ対策を検証します。
6. **運用と保守:** このフェーズでは、AI 製品が実稼働環境にある間、パフォーマンス、データドリフト、監査ログを継続的に監視し、異常やコンプライアンス違反のアラートをトリガーするとともに、定期的に最新データでモデルを再訓練し、セキュリティ、プライバシー、公平性のコントロールを再検証し、必要に応じてドキュメント、トレーニング、ポリシーを更新します。

AI システムが開始から継続的な運用まで正確、安全、公平、信頼を維持することを確保するには、AI テストは AI システムライフサイクル全体にわたって統合される必要があります。

1. **計画とスコープ設定のフェーズ:** ビジネス目標、成功指標、ML ユースケースがテスト可能かつ追跡可能であることを確認します。AI 固有のリスク (敵対的リスク、プライバシーリスク、コンプライアンスリスク) を特定し、それらをコントロールにマップします。利害関係者の役割、規制上の制約、リスク許容基準が文書化されていることを検証します。
2. **データ準備:** データ品質テストを実施し、欠損値、外れ値、スキーマの不一致、重複についてチェックします。特徴量分布 (つまり特定の変数量がどのように分布または配置されているか) を履歴プロファイルに対して検証し、ドリフト閾値 (つまりこのベースラインからのデータドリフトに対して) を設定します。すべてのデータソース、変換、バージョンが記録され、追跡可能であることを確認します。
3. **モデルの開発とトレーニング:** 前処理コード、カスタムレイヤ、特徴量エンジニアリング関数が期待通りに動作することを検証します。モデルコードに対して安全でない依存関係や構成ミスについて静的コードスキャン (SAST など) を実行します。トレーニング、バリデーション、テストのスプリット間でデータ漏洩がないことを確認します。チューニングの変更が回帰なしで汎化を向上することを確認します。
4. **バリデーションと評価:** ホールドアウトおよび敵対的テストセットにおいて、正確さ、適合率/再現率、AUC などを測定するためのベンチマークに対するパフォーマンスを検証します。公平性とバイアスの監査を実施し、人口統計スライスおよびエッジケースにわたってモデル出力を評価します。ニューラルネットワークやその他の敵対的攻撃に対する敵対的サンプルを細工するための既知の技法を適用することで、敵対的堅牢性テストを実施し、体制を評価します。プライバシー攻撃を実施し、メンバーシップ推論、モデル抽出、ポイズニングをシミュレートしてプライバシー保護を確認します。予測を入力特徴量に帰属することにより、モデルの決定が解釈可能かつ妥当であることを検証します。
5. **運用と保守:** 実稼働の入力と出力をバリデーションベースラインと継続的に比較することにより、ドリフト検出のための回帰テストを実施します。パフォーマンス低下、データドリフト、セキュリティ異常の際に監視ルールが正しく発火することを検証します。モデルアップデートまたはデータリフレッシュ後に、パフォーマンス、公平性、堅牢性を再評価します。セキュリティ、プライバシー、倫理的コントロールが引き続き有効であり、文書化されていることを定期的に確認します。

このガイドのテスト目標の一つは、OWASP の LLM 固有のテストケースと、より広範な OWASP AI Exchange \[5\] の脅威をライフサイクルフェーズに統合し、リリース前バリデーションと新たな脆弱性に対する継続的な保護の両方を確保することです。たとえば、計画とスコープ設定のフェーズで、脅威モデリング演習を使用して、OWASP Top 10 LLM リスク (プロンプトインジェクション、データ漏洩、モデルポイズニング、過度の依存など) と AI Exchange の脅威を列挙し、テストスコープとコントロールを定義できます。

たとえば、バリデーションと評価のフェーズでは、プロンプトインジェクションテストで直接および間接プロンプト不正操作をテストし、ガードレールのカバレッジと拒否動作を検証します。また、制御された再トレーニングループに悪意のあるサンプルを注入して、ポイズニング防御が機能することを確認します。開発と運用では、新しくインストールまたはアップデートされたプラグインを継続的にスキャンして、OWASP で特定された弱点を検出し、ジェイルブレイク、バックドアプロンプト、既知の OWASP AI Exchange 脅威ベクトルの悪用の兆候がないか、出力を監視するようにテストを指示できます。

この初期リリースでは、OWASP AI テスト方法論は AI 製品の所有者をガイドすることに重点を置いており、AI 製品の初期バージョンがテスト準備できたら、テストスコープを定義し、包括的な一連の評価を実行できます。今後のアップデートではこのガイダンスを拡張し、より初期の試作フェーズもカバーする予定です。
