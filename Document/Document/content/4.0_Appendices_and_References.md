
# **4. 付録と参考情報 (Appendices and References)**

### **はじめに**

この章は OWASP AI テストガイドの本文を補完するすべての関連資料を提供します。
付録は、構造化されたフレームワーク、脅威モデル、リスクライフサイクル、ドメイン固有のガイダンスを提供し、ガイドで提案されている方法論を補強します。

これらのリソースは三つの主要な目標に役立ちます。

1. 本書で前述した概念を **深化** する。
2. モデル、マッピング、方法論を通じて AI テストを **運用化** する。
3. ガイドを、認知されている業界標準、セキュリティ分類、学術文献に **基づく** ようにする。

この章はガイド全体を使用されているすべての情報源を記載した **参考情報** セクションで締めくくります。

### **4.1 付録 A: SAIF (Secure AI Framework) を使用する理由 (Appendix A: Rationale for Using SAIF (Secure AI Framework))**

付録 A では信頼できる AI 開発とテストの基盤モデルとして **Secure AI Framework (SAIF)** を採用する理由について紹介します。

SAIF は以下を提供します。

* データ、モデル、アプリケーション、インフラストラクチャの各層をカバーする包括的な構造
* AI システムに合わせた secure-by-design の観点
* モダンなリスク分類法とガバナンスフレームワークとの整合
* 脅威、リスク、アーキテクチャに関する付録との概念的な連続性

この付録では、AI が従来のソフトウェアテストパラダイムを超えたフレームワークを必要とする理由を説明します。

### **4.2 付録 B: 分散型、不変的、一時的 (DIE) 脅威の特定 (Appendix B: Distributed, Immutable, Ephemeral (DIE) Threat Identification)**

この付録では、クラウドネイティブおよび最新の AI 環境における脅威を特定するためのレンズとして **DIE モデル** -分散型、不変的、一時的- を紹介します。

AI システムは多くの場合以下を含みます。

* 分散コンピューティングクラスタ
* 不変アーティファクト (コンテナ、モデルバイナリなど)
* 一時的ジョブ (トレーニングパイプライン、マイクロサービスなど)

これらの特定は特有の攻撃対象領域を生み出します。
DIE フレームワークはテスト担当者が、サプライチェーンインジェクション、汚染されたアーティファクト、ワークフロー操作、クラウド環境の悪用といった脅威を認識するのに役立ちます。

### **4.3 付録 C: 安全な AI システムのためのリスクライフサイクル (Appendix C: Risk Lifecycle for Secure AI Systems)**

付録 C では、AI システムの動的かつ進化する性質を反映した **AI 特有のリスクライフサイクル** について説明します。

ライフサイクルは以下を含みます。

* リスクの特定
* 発生可能性と影響の評価
* 緩和戦略の設計
* ドリフトや敵対的操作の監視
* 残存リスクのレビューとコントロールの更新

データドリフト、モデルドリフト、フィードバックループリスクなど、AI システムに特有の現象に特に注意を払います。

### **4.4 付録 D: AI アーキテクチャコンポーネントへの脅威の列挙 (Appendix D: Threat Enumeration to AI Architecture Components)**

This appendix provides a structured mapping of **threats across AI architectural components**, including:

* data layer,
* model layer,
* application/API layer,
* infrastructure and deployment environment.

For each component, the appendix details:

* key threat vectors,
* typical vulnerabilities,
* propagation effects across layers.

This enumeration forms the basis for the testing procedures defined earlier in the guide.

### **4.5 付録 E: AI コンポーネント脆弱性 (CVE および CWE) への AI 脅威のマッピング (Appendix E: Mapping AI Threats Against AI System Vulnerabilities (CVEs & CWEs))**

Appendix E connects AI-specific threats to established vulnerability taxonomies such as:

* **CWE** (Common Weakness Enumeration),
* **CVE** (Common Vulnerabilities and Exposures),
* relevant MITRE classifications.

This mapping demonstrates how threats like model extraction, prompt injection, and training data leakage relate to traditional software weakness classes.
The goal is to integrate AI-security testing with existing enterprise vulnerability management workflows.

### **4.6 参考情報 (References)**

The final section compiles all sources cited throughout this guide, including standards, academic research, industry papers, and open-source projects.
These references provide the foundational material supporting the frameworks, methodologies, and recommendations outlined in the OWASP AI Testing Guide.
