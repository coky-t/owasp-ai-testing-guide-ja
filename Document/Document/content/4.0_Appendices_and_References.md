
# **4. 付録と参考情報 (Appendices and References)**

### **はじめに**

この章は OWASP AI テストガイドの本文を補完するすべての関連資料を提供します。
付録は、構造化されたフレームワーク、脅威モデル、リスクライフサイクル、ドメイン固有のガイダンスを提供し、ガイドで提案されている方法論を補強します。

これらのリソースは三つの主要な目標に役立ちます。

1. 本書で前述した概念を **深化** する。
2. モデル、マッピング、方法論を通じて AI テストを **運用化** する。
3. ガイドを、認知されている業界標準、セキュリティ分類、学術文献に **基づく** ようにする。

この章はガイド全体を使用されているすべての情報源を記載した **参考情報** セクションで締めくくります。

### **4.1 付録 A: SAIF (Secure AI Framework) を使用する理由 (Appendix A: Rationale for Using SAIF (Secure AI Framework))**

付録 A では信頼できる AI 開発とテストの基盤モデルとして **Secure AI Framework (SAIF)** を採用する理由について紹介します。

SAIF は以下を提供します。

* データ、モデル、アプリケーション、インフラストラクチャの各層をカバーする包括的な構造
* AI システムに合わせた secure-by-design の観点
* モダンなリスク分類法とガバナンスフレームワークとの整合
* 脅威、リスク、アーキテクチャに関する付録との概念的な連続性

この付録では、AI が従来のソフトウェアテストパラダイムを超えたフレームワークを必要とする理由を説明します。

### **4.2 付録 B: 分散型、不変的、一時的 (DIE) 脅威の特定 (Appendix B: Distributed, Immutable, Ephemeral (DIE) Threat Identification)**

This appendix presents the **DIE model**—Distributed, Immutable, Ephemeral—as a lens for identifying threats in cloud-native and modern AI environments.

AI systems often include:

* distributed compute clusters,
* immutable artifacts (e.g., containers, model binaries),
* ephemeral jobs (e.g., training pipelines, microservices).

These characteristics create unique attack surfaces.
The DIE framework helps testers recognize threats such as: supply-chain injection, poisoned artifacts, workflow manipulation, and cloud environment exploitation.

### **4.3 付録 C: 安全な AI システムのためのリスクライフサイクル (Appendix C: Risk Lifecycle for Secure AI Systems)**

Appendix C describes the **AI-specific risk lifecycle**, reflecting the dynamic and evolving nature of AI systems.

The lifecycle includes:

* identifying risks,
* assessing likelihood and impact,
* designing mitigation strategies,
* monitoring for drift or adversarial manipulation,
* reviewing residual risk and updating controls.

Special attention is given to phenomena unique to AI systems, such as data drift, model drift, and feedback-loop risks.

### **4.4 付録 D: AI アーキテクチャコンポーネントへの脅威の列挙 (Appendix D: Threat Enumeration to AI Architecture Components)**

This appendix provides a structured mapping of **threats across AI architectural components**, including:

* data layer,
* model layer,
* application/API layer,
* infrastructure and deployment environment.

For each component, the appendix details:

* key threat vectors,
* typical vulnerabilities,
* propagation effects across layers.

This enumeration forms the basis for the testing procedures defined earlier in the guide.

### **4.5 付録 E: AI コンポーネント脆弱性 (CVE および CWE) への AI 脅威のマッピング (Appendix E: Mapping AI Threats Against AI System Vulnerabilities (CVEs & CWEs))**

Appendix E connects AI-specific threats to established vulnerability taxonomies such as:

* **CWE** (Common Weakness Enumeration),
* **CVE** (Common Vulnerabilities and Exposures),
* relevant MITRE classifications.

This mapping demonstrates how threats like model extraction, prompt injection, and training data leakage relate to traditional software weakness classes.
The goal is to integrate AI-security testing with existing enterprise vulnerability management workflows.

### **4.6 参考情報 (References)**

The final section compiles all sources cited throughout this guide, including standards, academic research, industry papers, and open-source projects.
These references provide the foundational material supporting the frameworks, methodologies, and recommendations outlined in the OWASP AI Testing Guide.
