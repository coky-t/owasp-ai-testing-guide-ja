
# 3.2 AI モデルテスト (AI Model Testing)

**AI モデルテスト** カテゴリは、デプロイメントコンテキストとは独立して、AI モデル自体の脆弱性と堅牢性に対処します。このカテゴリは AI モデルの固有の特性と動作を特にターゲットにし、敵対的な状況下でも確実に実行し、機密情報を漏洩せず、意図した目標に沿うように維持するようにします。

モデルレベルのテストは、回避攻撃、データポイズニング、プライバシー漏洩、ミスアライメント問題への影響の受けやすさといった根本的な弱点を検出するのに役立ちます。包括的なモデルテストは AI システムの完全性、セキュリティ、信頼性を維持するために不可欠です。

### このテストカテゴリのスコープ (Scope of This Testing Category)

このカテゴリは AI モデルが以下であるかどうかを評価します。

- **敵対的回避攻撃** に対して堅牢で耐性がある  
  → [AITG-MOD-01: 回避攻撃のテスト (Testing for Evasion Attacks)](tests/AITG-MOD-01_Testing_for_Evasion_Attacks.md)

- **ランタイムモデルポイズニング** に対して効果的に保護する  
  → [AITG-MOD-02: ランタイムモデルポイズニングのテスト (Testing for Runtime Model Poisoning)](tests/AITG-MOD-02_Testing_for_Runtime_Model_Poisoning.md)

- **トレーニング時のポイズニング攻撃** に耐性がある  
  → [AITG-MOD-03: 汚染されたトレーニングセットのテスト (Testing for Poisoned Training Sets)](tests/AITG-MOD-03_Testing_for_Poisoned_Training_Sets.md)  


- 推論攻撃や反転攻撃に対して **データプライバシー** を保護する  
  → [AITG-MOD-04: メンバーシップ推論のテスト (Testing for Membership Inference)](tests/AITG-MOD-04_Testing_for_Membership_Inference.md)  
  → [AITG-MOD-05: 反転攻撃のテスト (Testing for Inversion Attacks)](tests/AITG-MOD-05_Testing_for_Inversion_Attacks.md)

- **新しいデータや敵対的データが提示された場合に頑健性** を維持する  
  → [AITG-MOD-06: 新しいデータに対する頑健性のテスト (Testing for Robustness to New Data)](tests/AITG-MOD-06_Testing_for_Robustness_to_New_Data.md)

- **事前定義した目標と制約に準拠** を一貫して継続する  
  → [AITG-MOD-07: 目標との整合のテスト (Testing for Goal Alignment)](tests/AITG-MOD-07_Testing_for_Goal_Alignment.md)

AI モデルテストカテゴリ内の各テストは、AI モデルの基本的な耐性、信頼性、安全性を確保し、すべてのデプロイメントとアプリケーションにわたるシステムリスクを軽減するのに役立ちます。
