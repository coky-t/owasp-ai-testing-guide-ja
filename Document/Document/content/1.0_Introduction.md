# 1. はじめに

### AI テストの重要性

AI テストは重要です。なぜなら AI は今や、医療や金融から自動車やサイバーセキュリティまで、あらゆる業界の重要な意思決定と日常業務の基盤となっています。AI システムが真に信頼性が高く、安全で、正確で、倫理的であることを確保するには、基本的な機能性をはるかに超えるテストが必要です。差別を防ぐためのバイアスと公平性のコントロールを検証し、モデルを欺いたり乗っ取るために細工された入力に対して敵対的堅牢性チェックを実施し、モデル抽出、データ漏洩、ポイズニング攻撃のシミュレーションといったセキュリティとプライバシーの評価を行う必要があります。差分プライバシーなどの技法を組み込むことで、データ保護法への準拠を確保しながら、個人の記録を保護します。
このガイドの AI テストに対する包括的なアプローチは、隠れたリスクを明らかにし、AI 主導のソリューションに対する信頼を維持することを目的としています。

### AI テストがユニークな理由

AI システムのテストは、従来のソフトウェアテストと比較して、特有の課題を伴います。AI モデル、特に機械学習 (ML) に基づくモデルは、非決定論的な動作を示します。多くの AI アルゴリズムはランダム性を伴うため、トレーニング時または推論時の出力は再現性がなく確率的になります。これは、許容可能な変動を考慮した、専用の回帰テストと安定性テストが必要です。AI モデルはトレーニングデータの品質と分布から学習して依存します。従来のコードとは異なり、入力の変化 (データドリフト) はパフォーマンスを徐々に低下する可能性があり、テストはデータ品質とモデル出力の両方を時間の経過とともに検証する必要があります。


AI システムはトレーニングデータと入力データの品質と完全性に大きく依存するため、信頼性、公平性、正確性の高いモデルパフォーマンスを確保するには、データ中心のテスト方法論が不可欠となります。トレーニングデータに潜む意図しないバイアスは、差別的な結果につながる可能性があります。AI テストは、従来のソフトウェア QA には含まれない、公平性評価と緩和戦略を含む必要があります。ディープラーニングニューラルネットワークなど、一部の AI システムの複雑性と「ブラックボックス」的な性質は、内部の意思決定プロセスを不明瞭にし、検証と妥当性確認を複雑にする可能性があります。敵対的または攻撃的なセキュリティテストは推奨されるだけでなく、AI テクノロジにとって不可欠です。


AI モデルは、巧妙に細工された入力 (敵対的サンプル) によって欺かれたり操作される可能性があるため、組織は標準的な機能テストをはるかに超える専用の敵対的堅牢性テスト方法論を採用する必要があります。これらの専門的なセキュリティ評価がなければ、AI システムは完全性、信頼性、全体的な信憑性を損なう可能性のある巧妙な攻撃に脆弱なままとなります。


最後に、すべての AI モデルは絶えず変化する環境で稼働しているため、ドリフト、新たなバイアス、新しい脆弱性を捕捉するには、データとモデルのパフォーマンスの両方を継続的に監視し、自動的に再検証することが不可欠です。


### OWASP AI テストガイドの目的とスコープ

OWASP AI テストガイドは、ソフトウェア開発者、アーキテクト、データアナリスト、研究者、リスク担当者にとっての包括的なリファレンスとして機能するように設計されており、製品開発ライフサイクル全体を通じて AI リスクが体系的に対処されることを確保します。データ中心バリデーションと公平性評価から敵対的堅牢性と継続的なパフォーマンス監視に至るまで、リスクのバリデーションとコントロールの文書化された証跡を総合的に提供する、堅牢なテストスイートを概説しています。このガイダンスに従うことで、チームは AI システムを自信を持って本番環境にデプロイするために必要なレベルの信頼を確立し、潜在的なバイアス、脆弱性、パフォーマンス低下が事前に特定されて緩和される、検証可能な保証を得ることが可能です。
