
# 3.2 AI モデルテスト (AI Model Testing)

**AI モデルテスト** カテゴリは、AI モデルのデプロイメントコンテキストとは独立して、AI モデル自体の脆弱性と堅牢性に対処します。このカテゴリは AI モデルの固有の特性と動作を特にターゲットにし、敵対的な状況下でも確実に実行し、機密情報を漏洩せず、意図した目標に沿うように維持するようにします。

モデルレベルのテストは、回避攻撃、データポイズニング、プライバシー漏洩、ミスアライメント問題への影響の受けやすさといった根本的な弱点を検出するのに役立ちます。包括的なモデルテストは AI システムの完全性、セキュリティ、信頼性を維持するために不可欠です。

### このテストカテゴリのスコープ (Scope of This Testing Category)

This category evaluates whether the AI model:

- Is robust and resilient against **adversarial evasion attacks**  
  → [AITG-MOD-01: Testing for Evasion Attacks](/Document/content/tests/AITG-MOD-01_Testing_for_Evasion_Attacks.md)

- Protects effectively against **runtime model poisoning**  
  → [AITG-MOD-02: Testing for Runtime Model Poisoning](/Document/content/tests/AITG-MOD-02_Testing_for_Runtime_Model_Poisoning.md)

- Is resistant to **training-time poisoning attacks**  
  → [AITG-MOD-03: Testing for Poisoned Training Sets](/Document/content/tests/AITG-MOD-03_Testing_for_Poisoned_Training_Sets.md)  


- Preserves **data privacy** against inference and inversion attacks  
  → [AITG-MOD-04: Testing for Membership Inference](/Document/content/tests/AITG-MOD-04_Testing_for_Membership_Inference.md)  
  → [AITG-MOD-05: Testing for Inversion Attacks](/Document/content/tests/AITG-MOD-05_Testing_for_Inversion_Attacks.md)

- Maintains **robustness when presented with new or adversarial data**  
  → [AITG-MOD-06: Testing for Robustness to New Data](/Document/content/tests/AITG-MOD-06_Testing_for_Robustness_to_New_Data.md)

- Remains consistently **aligned with predefined goals and constraints**  
  → [AITG-MOD-07: Testing for Goal Alignment](/Document/content/tests/AITG-MOD-07_Testing_for_Goal_Alignment.md)

Each test within the AI Model Testing category helps ensure the fundamental resilience, reliability, and safety of AI models, reducing systemic risk across all deployments and applications.
