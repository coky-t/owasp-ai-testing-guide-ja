
# 3. AI テストガイドフレームワーク (AI Testing Guide Framework)

第 2 章で実施した脅威モデリングに基づいて、AI アーキテクチャの脅威を具体的なテストケースにマップする構造化されたフレームワークを定義できるようになります。このプロジェクトは従来のサイバーセキュリティ、MLOps テスト、責任ある AI 評価を統一された構造の下で橋渡しすることを目的としています。

各テストケースは以下の四つの柱のいずれかに分類されます。

- 🟦 [**AI アプリケーションテスト (AI Application Testing)**](3.1_AI_Application_Testing.md)
- 🟪 [**AI モデルテスト (AI Model Testing)**](3.2_AI_Model_Testing.md)
- 🟩 [**AI インフラストラクチャテスト (AI Infrastructure Testing)**](3.3_AI_Infrastructure_Testing.md)
- 🟨 [**AI データテスト (AI Data Testing)**](3.4_AI_Data_Testing.md)

分析を開始する前に、このタイプのテストの限界を考慮し、ブラックボックスアプローチからグレーボックスやホワイトボックスのアプローチに移行する可能性を検討することが重要です。これには追加情報を必要とします。**制限と要件** は次の節で説明します。


## 🟦 AI アプリケーションテスト (AI Application Testing)

| テスト ID   | テスト名とリンク      | 脅威の出典              | ドメイン  |
|-------------|-----------------------|-------------------------|-----------|
| AITG-APP-01 | [プロンプトインジェクションのテスト (Testing for Prompt Injection)](tests/AITG-APP-01_Testing_for_Prompt_Injection.md)                                   | OWASP Top 10 LLM 2025   | Security          |
| AITG-APP-02 | [間接プロンプトインジェクションのテスト (Testing for Indirect Prompt Injection)](tests/AITG-APP-02_Testing_for_Indirect_Prompt_Injection.md)             | OWASP Top 10 LLM 2025   | Security          |
| AITG-APP-03 | [機密データ漏洩のテスト (Testing for Sensitive Data Leak)](tests/AITG-APP-03_Testing_for_Sensitive_Data_Leak.md)                                         | OWASP Top 10 LLM 2025   | Security, Privacy |
| AITG-APP-04 | [入力漏洩のテスト (Testing for Input Leakage)](tests/AITG-APP-04_Testing_for_Input_Leakage.md)                                                           | OWASP Top 10 LLM 2025   | Security, Privacy |
| AITG-APP-05 | [安全でない出力のテスト (Testing for Unsafe Outputs)](tests/AITG-APP-05_Testing_for_Unsafe_Outputs.md)                                                   | OWASP Top 10 LLM 2025   | Security, RAI     |
| AITG-APP-06 | [エージェント動作限界のテスト (Testing for Agentic Behavior Limits)](tests/AITG-APP-06_Testing_for_Agentic_Behavior_Limits.md)                           | OWASP Top 10 LLM 2025   | Security, RAI     |
| AITG-APP-07 | [プロンプト開示のテスト (Testing for Prompt Disclosure)](tests/AITG-APP-07_Testing_for_Prompt_Disclosure.md)                                             | OWASP Top 10 LLM 2025   | Security, Privacy |
| AITG-APP-08 | [エンベディング操作のテスト (Testing for Embedding Manipulation)](tests/AITG-APP-08_Testing_for_Embedding_Manipulation.md)                               | OWASP Top 10 LLM 2025   | Security          |
| AITG-APP-09 | [モデル抽出のテスト (Testing for Model Extraction)](tests/AITG-APP-09_Testing_for_Model_Extraction.md)                                                   | OWASP AI Exchange       | Security          |
| AITG-APP-10 | [コンテンツバイアスのテスト (Testing for Harmful Content Bias)](tests/AITG-APP-10_Testing_for_Harmful_Content_Bias.md)                                   | OWASP Top 10 LLM 2025   | RAI               |
| AITG-APP-11 | [ハルシネーションのテスト (Testing for Hallucinations)](tests/AITG-APP-11_Testing_for_Hallucinations.md)                                                 | Responsible AI          | RAI               |
| AITG-APP-12 | [有害な出力のテスト (Testing for Toxic Output)](tests/AITG-APP-12_Testing_for_Toxic_Output.md)                                                           | Responsible AI          | RAI               |
| AITG-APP-13 | [AI への過度な依存のテスト (Testing for Over-Reliance on AI)](tests/AITG-APP-13_Testing_for_Over-Reliance_on_AI.md)                                      | Responsible AI          | RAI               |
| AITG-APP-14 | [説明可能性と解釈可能性のテスト (Testing for Explainability and Interpretability)](tests/AITG-APP-14_Testing_for_Explainability_and_Interpretability.md) | Responsible AI          | RAI               |

---

## 🟪 AI モデルテスト (AI Model Testing)

| テスト ID   | テスト名とリンク      | 脅威の出典              | ドメイン  |
|-------------|-----------------------|-------------------------|-----------|
| AITG-MOD-01 | [回避攻撃のテスト (Testing for Evasion Attacks)](tests/AITG-MOD-01_Testing_for_Evasion_Attacks.md)                                     | OWASP AI Exchange       | Security |
| AITG-MOD-02 | [ランタイムモデルポイズニングのテスト (Testing for Runtime Model Poisoning)](tests/AITG-MOD-02_Testing_for_Runtime_Model_Poisoning.md) | OWASP Top 10 LLM 2025   | Security |
| AITG-MOD-03 | [汚染されたトレーニングセットのテスト (Testing for Poisoned Training Sets)](tests/AITG-MOD-03_Testing_for_Poisoned_Training_Sets.md)   | OWASP Top 10 LLM 2025   | Security |
| AITG-MOD-04 | [メンバーシップ推論のテスト (Testing for Membership Inference)](tests/AITG-MOD-04_Testing_for_Membership_Inference.md)                 | OWASP AI Exchange       | Privacy  |
| AITG-MOD-05 | [反転攻撃のテスト (Testing for Inversion Attacks)](tests/AITG-MOD-05_Testing_for_Inversion_Attacks.md)                                 | OWASP AI Exchange       | Privacy  |
| AITG-MOD-06 | [新しいデータに対する頑健性のテスト (Testing for Robustness to New Data)](tests/AITG-MOD-06_Testing_for_Robustness_to_New_Data.md)     | Responsible AI          | RAI      |
| AITG-MOD-07 | [目標との整合のテスト (Testing for Goal Alignment)](tests/AITG-MOD-07_Testing_for_Goal_Alignment.md)                                   | Responsible AI          | RAI      |

## 🟩 AI インフラストラクチャテスト (AI Infrastructure Testing)

| テスト ID   | テスト名とリンク      | 脅威の出典              | ドメイン  |
|-------------|-----------------------|-------------------------|-----------|
| AITG-INF-01 | [サプライチェーン改竄のテスト (Testing for Supply Chain Tampering)](tests/AITG-INF-01_Testing_for_Supply_Chain_Tampering.md)           | OWASP Top 10 LLM 2025   | Security          |
| AITG-INF-02 | [リソース枯渇のテスト (Testing for Resource Exhaustion)](tests/AITG-INF-02_Testing_for_Resource_Exhaustion.md)                         | OWASP Top 10 LLM 2025   | Security          |
| AITG-INF-03 | [プラグイン境界違反のテスト (Testing for Plugin Boundary Violations)](tests/AITG-INF-03_Testing_for_Plugin_Boundary_Violations.md)     | Responsible AI          | RAI               |
| AITG-INF-04 | [ケイパビリティ不正使用のテスト (Testing for Capability Misuse)](tests/AITG-INF-04_Testing_for_Capability_Misuse.md)                   | Responsible AI          | RAI               |
| AITG-INF-05 | [ファインチューニングポイズニングのテスト (Testing for Fine-tuning Poisoning)](tests/AITG-INF-05_Testing_for_Fine-tuning_Poisoning.md) | OWASP Top 10 LLM 2025   | Security          |
| AITG-INF-06 | [開発時のモデル窃取のテスト (Testing for Dev-Time Model Theft)](tests/AITG-INF-06_Testing_for_Dev-Time_Model_Theft.md)                 | OWASP AI Exchange       | Security, Privacy |

---

## 🟨 AI データテスト (AI Data Testing)

| テスト ID   | テスト名とリンク      | 脅威の出典              | ドメイン  |
|-------------|-----------------------|-------------------------|-----------|
| AITG-DAT-01 | [トレーニングデータ露出のテスト (Testing for Training Data Exposure)](tests/AITG-DAT-01_Testing_for_Training_Data_Exposure.md)                         | OWASP AI Exchange       | Privacy           |
| AITG-DAT-02 | [ランタイム流出のテスト (Testing for Runtime Exfiltration)](tests/AITG-DAT-02_Testing_for_Runtime_Exfiltration.md)                                     | OWASP AI Exchange       | Security, Privacy |
| AITG-DAT-03 | [データセットの多様性とカバレッジのテスト (Testing for Dataset Diversity & Coverage)](tests/AITG-DAT-03_Testing_for_Dataset_Diversity_and_Coverage.md) | Responsible AI          | RAI               |
| AITG-DAT-04 | [データ内の有害なコンテンツのテスト (Testing for Harmful Content in Data)](tests/AITG-DAT-04_Testing_for_Harmful_Content_in_Data.md)                   | Responsible AI          | RAI               |
| AITG-DAT-05 | [データ最小化と同意のテスト (Testing for Data Minimization & Consent)](tests/AITG-DAT-05_Testing_for_Data_Minimization_and_Consent.md)                 | Responsible AI          | Privacy, RAI      |



## テストの制限と要件 (Testing Limitations and Requirements)

LLM/生成 AI システム、特にマルチエージェントアーキテクチャを使用している場合に、純粋なブラックボックステストを実施すると、大きな制限を生み、複雑さを増す可能性があります。

**ブラックボックスアプローチ** を用いて評価活動を計画する際には、以下の **制限** を考慮する必要があります。

- LLM モデルは **数値的な重みと数学関数** で構成されており、ソースコードに記載されたワークフローには従いません。従来のアプリケーションではソースコードを解析することで特定の問題の有無を特定できることが多いのですが、**生成 AI アプリケーションではこれが複雑になるか、まったく実現できないことがあります**。
- 多くの LLM モデルはゼロより大きい **温度 (temperature)** を使用します。温度はモデルの出力のランダム性を制御するパラメータです。温度が高いほど、より広範囲のトークンからサンプリングすることでランダム性と「創造性」を増し、より多様で、決定論的ではない出力を生成します。これは、**攻撃ベクトルを複数回繰り返す** 必要が生じる可能性があり、結果は **再現が困難** になる可能性があります。温度がゼロの場合でも、浮動小数点演算の非結合性により、評価バッチサイズ、GPU 数、または GPU バージョンを変更すると、結果が再現できなくなり、大幅に異なる可能性があります。
- **ガードレール** 自体は LLM モデルを使用して実装されることが多く、解析がさらに複雑になります。
- **複数のエージェント** で構成される生成 AI アプリケーションでは、ユーザーの入力は一般的に最初のプロンプトに含まれ、最初の LLM エージェントの出力が次のものに対する入力になります。このプロセスは、生成 AI システムのアーキテクチャとユーザーによって提供される具体的な入力に応じて、複数回繰り返される可能性があります。このようなアーキテクチャでは、アプリケーションのさまざまなコンポーネントすべてを効果的に検証することは特に複雑であり、**そのような解析に必要な時間とリクエストの数は法外なほどに多くなるか、場合によってはまったく実現できない可能性があります**。
- 多くの生成 AI アプリケーションは **業界の主要企業が提供する外部モデル** に依存しています。これらのモデルは通常 **入力と出力の両方で処理されるトークンの数に基づいたコスト** がかかります。一部のモデルでは、このコストが重大となる可能性があり、**大規模な自動テストを検討する前に** 考慮する必要があります。このため、そのようなアプリケーションではトークン消費を制限するための閾値を持つことが多く、トークンを制御不能に使用すると **サービス拒否 (DoS) やウォレット拒否 (DoW) 状態** につながる可能性があります。また、マルチエージェントシステムでは、トークン消費がユーザーの入力とアプリケーションの最終出力に限定されず、エージェント間で交換されるすべての中間プロンプトと出力も含むことを考慮することも重要です。これによりトークン使用全体の大幅な増加をもたらすことがよくあります。

以下の **要件** では時間とリソースの消費を減らしてより良い結果を得ることができますが、より多くの情報が必要になるため、**よりグレーボックスやホワイトボックスのアプローチを必要とします**。

- **詳細なアプリケーションログ** へのアクセス: 生成 AI アプリケーション、特にマルチエージェントアーキテクチャを備えたもの、の開発では、エージェント間のやり取りや、それらが受信および生成する入出力を可視化するために、開発者は一般的にログ記録ツールを採用します。そのようなツールにアクセスすることで **より的を絞ったテストを可能** にし、トークンの使用と検証時間という点でリソース消費を軽減します。
- **プロンプト、アーキテクチャ、ソースコード** へのアクセス: テスト時に利用できる情報が多いほど、特定のアプリケーションとそのプロンプトに調整されたテストを実行できるようになり、**必要なテスト数と所要時間の両方を軽減します**。生成 AI テストでは、前述の制限 (温度、コストなど) があるため、これは **標準的なアプリケーションテストよりもはるかに重要です**。
- **サードパーティサービスの管理コンソールへの読み取りアクセス**: サードパーティ LLM に基づくアプリケーションの使用に関連する重大なリスク (サービス拒否やウォレット拒否など) を評価するには、これらのサービスの構成を分析する必要があります。このような管理コンソールには **使用中のモデル、コストと閾値、ログ、ガードレール構成、ソースコード、実装されたソリューションのアーキテクチャに関する詳細** を含むことがあります。
